{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theoretical Backgrounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstructing MNIST images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tqdm\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now load the data. Because the MNIST dataset is quite large, we import only the training dataset, which consists of 60000 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ../../data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load MNIST dataset\n",
    "\n",
    "mnist_dataset = MNIST(\n",
    "    root='../../data',\n",
    "    train=True,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "mnist_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_dataset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten the images\n",
    "X_data = mnist_dataset.data.view(-1, 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_data, \n",
    "    mnist_dataset.targets, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: torch.Size([48000, 784])\n",
      "X_test.shape: torch.Size([12000, 784])\n",
      "y_train.shape: torch.Size([48000])\n",
      "y_test.shape: torch.Size([12000])\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train.shape: {X_train.shape}\")\n",
    "print(f\"X_test.shape: {X_test.shape}\")\n",
    "print(f\"y_train.shape: {y_train.shape}\")\n",
    "print(f\"y_test.shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Scale the data so that they have zero mean and unit variance\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(X_train, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(X_test, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design a sparse autoencoder\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dims[0])\n",
    "        self.fc2 = nn.Linear(hidden_dims[0], hidden_dims[1])\n",
    "        self.fc3 = nn.Linear(hidden_dims[1], hidden_dims[2])\n",
    "        self.fc4 = nn.Linear(hidden_dims[2], latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dims, output_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(latent_dim, hidden_dims[2])\n",
    "        self.fc2 = nn.Linear(hidden_dims[2], hidden_dims[1])\n",
    "        self.fc3 = nn.Linear(hidden_dims[1], hidden_dims[0])\n",
    "        self.fc4 = nn.Linear(hidden_dims[0], output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims, latent_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = Encoder(input_dim, hidden_dims, latent_dim)\n",
    "        self.decoder = Decoder(latent_dim, hidden_dims, input_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Autoencoder(\n",
       "  (encoder): Encoder(\n",
       "    (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
       "    (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (fc4): Linear(in_features=64, out_features=16, bias=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (fc1): Linear(in_features=16, out_features=64, bias=True)\n",
       "    (fc2): Linear(in_features=64, out_features=128, bias=True)\n",
       "    (fc3): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (fc4): Linear(in_features=256, out_features=784, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "hidden_dims = [256, 128, 64]\n",
    "latent_dim = 16\n",
    "lr = 1e-3\n",
    "num_epochs = 10\n",
    "\n",
    "autoencoder = Autoencoder(input_dim=input_dim, hidden_dims=hidden_dims, latent_dim=latent_dim)\n",
    "autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|   10/10 [  00:46<  00:00,  4.67s/ep, Loss:  1317.40, avg loss:  1748.31]\n"
     ]
    }
   ],
   "source": [
    "# Train the autoencoder\n",
    "\n",
    "optimizer = optim.Adam(autoencoder.parameters(), lr=lr)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss_history = []\n",
    "\n",
    "bar_format = '{l_bar}{bar:10}| {n:4}/{total_fmt} [{elapsed:>7}<{remaining:>7}, {rate_fmt}{postfix}]'\n",
    "progress_bar = tqdm.trange(num_epochs, unit=\"ep\", bar_format=bar_format, ascii=True)\n",
    "\n",
    "for i in progress_bar:\n",
    "\n",
    "    total_loss = 0\n",
    "    for i, x in enumerate(train_loader):\n",
    "        inputs = x.type(torch.float32).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = autoencoder(inputs)\n",
    "        loss = criterion(outputs, inputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "        loss_history.append(loss.item())\n",
    "    loss_avg = np.mean(loss_history)\n",
    "\n",
    "    progress_bar.set_postfix_str(f\"Loss: {loss: 7.2f}, avg loss: {loss_avg: 7.2f}\")\n",
    "    progress_bar.update(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 3142.9654\n",
      "Epoch 2/10, Loss: 5196.4968\n",
      "Epoch 3/10, Loss: 7018.3595\n",
      "Epoch 4/10, Loss: 8682.3663\n",
      "Epoch 5/10, Loss: 10238.5985\n",
      "Epoch 6/10, Loss: 11705.2416\n",
      "Epoch 7/10, Loss: 13121.9792\n",
      "Epoch 8/10, Loss: 14500.9964\n",
      "Epoch 9/10, Loss: 15843.4386\n",
      "Epoch 10/10, Loss: 17153.2524\n"
     ]
    }
   ],
   "source": [
    "# Train the autoencoder\n",
    "\n",
    "optimizer = optim.Adam(autoencoder.parameters(), lr=lr)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "total_loss = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, x in enumerate(train_loader):\n",
    "        inputs = x.type(torch.float32).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = autoencoder(inputs)\n",
    "        loss = criterion(outputs, inputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality reduction "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
